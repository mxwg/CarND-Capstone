{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_RED = 'red'\n",
    "COLOR_GREEN = 'green'\n",
    "COLOR_YELLOW = 'yellow'\n",
    "\n",
    "COLOR_RED_NUM = 1\n",
    "COLOR_GREEN_NUM = 2\n",
    "COLOR_YELLOW_NUM = 3\n",
    "\n",
    "def getLabel(init_label):\n",
    "    return {\n",
    "        'stop': COLOR_RED,\n",
    "        'go': COLOR_GREEN,\n",
    "        'goLeft': COLOR_GREEN,\n",
    "        'warning': COLOR_YELLOW,\n",
    "        'warningLeft': COLOR_YELLOW,\n",
    "        'stopLeft': COLOR_RED,\n",
    "        'goForward': COLOR_GREEN\n",
    "    }[init_label]\n",
    "\n",
    "def getNumericLabel(text_label):\n",
    "    return {\n",
    "        COLOR_RED: COLOR_RED_NUM,\n",
    "        COLOR_GREEN: COLOR_GREEN_NUM,\n",
    "        COLOR_YELLOW: COLOR_YELLOW_NUM\n",
    "    }[text_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnnotations(images_path, annotations_path):\n",
    "    global filenames, labels, boxes\n",
    "    with open(annotations_path) as annotations:\n",
    "        reader = csv.DictReader(annotations, delimiter=';')\n",
    "        for row in reader:\n",
    "            filenames.append(images_path + (row['Filename'].split('/'))[1])\n",
    "            labels.append(getLabel(row['Annotation tag']))\n",
    "            boxes_tmp = [row['Upper left corner X'], row['Upper left corner Y'], row['Lower right corner X'], row['Lower right corner Y']]\n",
    "            boxes.append(boxes_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/daySequence1/frames/daySequence1--00000.jpg\n",
      "Number of files: 18020\n"
     ]
    }
   ],
   "source": [
    "labels_path = './data/Annotations/'\n",
    "\n",
    "filenames = []\n",
    "labels = []\n",
    "boxes = []\n",
    "images = []\n",
    "\n",
    "images_path = './data/daySequence1/frames/'\n",
    "annotations_path = labels_path + 'daySequence1/frameAnnotationsBOX.csv'\n",
    "getAnnotations(images_path, annotations_path)\n",
    "        \n",
    "images_path = './data/daySequence2/frames/'\n",
    "annotations_path = labels_path + 'daySequence2/frameAnnotationsBOX.csv'\n",
    "getAnnotations(images_path, annotations_path)\n",
    "print(filenames[0])\n",
    "print('Number of files: ' + str(len(filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateImages():\n",
    "    i=-1\n",
    "    for file in filenames:\n",
    "        i+=1\n",
    "        image = Image.open(file)\n",
    "        with tf.gfile.GFile(file, 'rb') as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        w, h = image.size[:2]\n",
    "        if image is None:\n",
    "            print('error')\n",
    "        else:\n",
    "            yield i, file, encoded_jpg, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTFRecord(height, width, filename, image, image_format, boxes, labels_text, labels):\n",
    "    xmin, ymin, xmax, ymax = list(map(int, boxes))\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(image),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature([xmin/w]),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature([xmax/w]),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature([ymin/h]),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature([ymax/h]),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature([labels_text]),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature([labels]),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18019 records saved.\n",
      "TFRecords saved\n"
     ]
    }
   ],
   "source": [
    "#get TFRecords:\n",
    "writer = tf.python_io.TFRecordWriter('train.record')\n",
    "for i, f, img, w ,h in generateImages():\n",
    "    raw_filename = f.encode('utf8')\n",
    "    raw_label = labels[i].encode('utf8')\n",
    "    raw_label_num = getNumericLabel(labels[i])\n",
    "    TFRecord = prepareTFRecord(h, w, raw_filename, img, b'jpg', boxes[i], raw_label, raw_label_num)\n",
    "    writer.write(TFRecord.SerializeToString())\n",
    "print(\"{} records saved.\".format(i))\n",
    "writer.close()\n",
    "print('TFRecords saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boxes', 158200),\n",
       " ('filenames', 158200),\n",
       " ('labels', 158200),\n",
       " ('img', 136715),\n",
       " ('generateImages', 136),\n",
       " ('getAnnotations', 136),\n",
       " ('getLabel', 136),\n",
       " ('getNumericLabel', 136),\n",
       " ('prepareTFRecord', 136),\n",
       " ('annotations_path', 104),\n",
       " ('f', 99),\n",
       " ('TFRecord', 88),\n",
       " ('raw_filename', 83),\n",
       " ('Image', 80),\n",
       " ('dataset_util', 80),\n",
       " ('np', 80),\n",
       " ('tf', 80),\n",
       " ('images_path', 76),\n",
       " ('labels_path', 68),\n",
       " ('images', 64),\n",
       " ('writer', 56),\n",
       " ('COLOR_YELLOW', 55),\n",
       " ('COLOR_GREEN', 54),\n",
       " ('COLOR_RED', 52),\n",
       " ('raw_label', 38),\n",
       " ('COLOR_GREEN_NUM', 28),\n",
       " ('COLOR_RED_NUM', 28),\n",
       " ('COLOR_YELLOW_NUM', 28),\n",
       " ('h', 28),\n",
       " ('i', 28),\n",
       " ('raw_label_num', 28),\n",
       " ('w', 28)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yellow', 'green', 'red'}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
